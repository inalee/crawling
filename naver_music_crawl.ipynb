{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] begin_year end_year begin_month end_month\n",
      "ipykernel_launcher.py: error: argument begin_year: invalid int value: 'C:\\\\Users\\\\Ina Lee\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-6b31b3f5-cec7-4bcf-900a-89d7bcebacb8.json'\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "# %load lyrics_crawl_preprocessing.py\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from pandas import DataFrame\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.alert import Alert\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoAlertPresentException\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('begin_year', type=int, help='beginning year you wanna crawl')\n",
    "parser.add_argument('end_year', type=int, help='end year you wanna crawl')\n",
    "parser.add_argument('begin_month', type=int, help='beginning month you wanna crawl')\n",
    "parser.add_argument('end_month', type=int, help='end month you wanna crawl')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "\"\"\"\n",
    "begin_year = args.begin_year\n",
    "end_year = args.end_year\n",
    "begin_month = args.begin_month\n",
    "end_month = args.end_month\n",
    "\"\"\"\n",
    "\n",
    "begin_year = 2019\n",
    "end_year = 2019\n",
    "begin_month = 1\n",
    "end_month = 3\n",
    "\n",
    "# track information sheet\n",
    "years_list = []\n",
    "months_list = []\n",
    "weeks_list = []\n",
    "ranks_list = []\n",
    "artists_list = []\n",
    "titles_list = [] # song's title\n",
    "trackId_list = []\n",
    "genre_list = []\n",
    "release_list = [] # release_date\n",
    "notes_list = [] # list for special case. classify track that 19+(for only adult), track that doesn't exist anymore, track that doesn't have lyric, track that doesn't provide service(can't play).\n",
    "number_of_lines_list = [] # lyric's number of lines\n",
    "entire_lyric_trackId_list = [] # list for entire lyric's track identifier\n",
    "# 가사 분석을 순수 한글로만 이루어진 가사 데이터로만 진행하고 싶을때 사용하기 위함입니다.\n",
    "has_alphabet_list = [] # check if lyric has alphabet\n",
    "\n",
    "# lyric data sheet\n",
    "lyrics_list = []\n",
    "\n",
    "# lyric's sentences sheet\n",
    "line_list = [] # index for sentence's line\n",
    "sentence_data_list = [] # list for sentence data\n",
    "lyrics_sentence_trackId_list = [] # list for sentence's track identifier \n",
    "\n",
    "# edit with your path of chromedriver\n",
    "browser = webdriver.Chrome('/Users/pshkh/chromedriver_win32/chromedriver')\n",
    "\n",
    "# enter the naver's login page\n",
    "browser.get('https://nid.naver.com/nidlogin.login')\n",
    "\n",
    "# if you wanna crawl 19+ song, you have to login\n",
    "# 수동으로 네이버 로그인을 해줘야한다. 그것을 위한 10초 (캡차 회피 현존 방식은 전부 막힘)\n",
    "time.sleep(10)\n",
    "\n",
    "# period that you wanna crawl\n",
    "\n",
    "\"\"\"\n",
    "begin_year = args.begin_year\n",
    "end_year = args.end_year\n",
    "begin_month = args.begin_month\n",
    "end_month = args.end_month\n",
    "\"\"\"\n",
    "\n",
    "begin_year = 2019\n",
    "end_year = 2019\n",
    "begin_month = 1\n",
    "end_month = 3\n",
    "\n",
    "\n",
    "# pattern that I wanna replace\n",
    "rep = {'<br>':'\\n', '<br/>':'\\n', 'amp;':'', '-':' ', '_':'', '—':''}\n",
    "# use these three lines to do the replacement\n",
    "rep = dict((re.escape(k), v) for k, v in rep.items())\n",
    "pattern = re.compile(\"|\".join(rep.keys()))\n",
    "def remove_tags(lyrics):\n",
    "    # replace pattern that I defined above\n",
    "    lyrics = pattern.sub(lambda m: rep[re.escape(m.group(0))], lyrics)\n",
    "    # remove [text] and <text>    \n",
    "    lyrics = re.sub(\"[\\<\\[].*?[\\>\\]]\", \"\", lyrics)\n",
    "    return lyrics\n",
    "\n",
    "for year in range(begin_year, end_year+1, 1):\n",
    "    for month in range(begin_month, end_month+1, 1):\n",
    "        browser.get(\"https://music.naver.com/listen/history/index.nhn?type=TOTAL&year=%d&month=%02d&week=%d\" % (year, month, 1))\n",
    "        html = browser.page_source\n",
    "        \n",
    "        # Check 4 weeks per a month or 5 weeks per a month\n",
    "        max_week = len(BeautifulSoup(html, \"lxml\").find_all('a', class_='_a_week'))-1\n",
    "\n",
    "        for week in range(1, max_week+1, 1):\n",
    "            # page 1 : Top 1~50, page 2 : Top 51~100\n",
    "            for page in range(0, 2):\n",
    "                browser.get(\"https://music.naver.com/listen/history/index.nhn?type=TOTAL&year=%d&month=%02d&week=%d&page=%d\" % (year, month, week, page+1))\n",
    "                html = browser.page_source\n",
    "\n",
    "                rankSoup = BeautifulSoup(html, \"lxml\")\n",
    "                \n",
    "                # information about tracks\n",
    "                tracks = rankSoup.find_all('tr', class_='_tracklist_move')\n",
    "                \n",
    "                # 서비스 중인 곡은 _title, 서비스 종료된 곡은 title\n",
    "                songs = rankSoup.find_all(['a', 'span'], class_=re.compile(r\"^(title|_title)$\")) \n",
    "                artists = rankSoup.find_all('td', class_='_artist')\n",
    "\n",
    "                rank = 1 # rank starts at 1\n",
    "                for song in songs:\n",
    "                    \n",
    "                    # index : 0 Trackid, 2 서비스 유무, 4 19금 유무, 9 가사 유무\n",
    "                    trackinfo = tracks[rank]['trackdata'].split('|') \n",
    "\n",
    "                    # for genre & release date\n",
    "                    urldata = urlopen(\"http://music.naver.com/track/index.nhn?trackId=%s\" % (trackinfo[0]))\n",
    "                    trackSoup = BeautifulSoup(urldata, \"html.parser\")\n",
    "                    try:\n",
    "                        trackdata = trackSoup.find(\"dl\", class_=\"desc\").find_all(\"dd\") # for genre & release date\n",
    "                    except AttributeError:\n",
    "                        # 트랙 없음\n",
    "                        genre_list.append('')   \n",
    "                        release_list.append('')\n",
    "                    else: \n",
    "                        genre_list.append(trackdata[1].text[1:])\n",
    "                        release_list.append(trackdata[2].text)\n",
    "\n",
    "                    if trackinfo[9] == 'true':\n",
    "                        browser.get(\"https://music.naver.com/lyric/index.nhn?trackId=%s\" % (trackinfo[0]))\n",
    "                        try:\n",
    "                            Alert(browser).accept()\n",
    "                            lyrics = ''  \n",
    "                            lyrics_sentence_list = ['']    \n",
    "                            note = '트랙 없음'\n",
    "\n",
    "                            if trackinfo[4] == 'true':\n",
    "                                note += '&19금'\n",
    "                            if trackinfo[2] == 'false':\n",
    "                                note += '&서비스 종료'\n",
    "                        except NoAlertPresentException:\n",
    "                            html = browser.page_source\n",
    "                            lyricsSoup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "                            lyrics = str(lyricsSoup.find('div', class_='show_lyrics'))\n",
    "                            \n",
    "                            lyrics = remove_tags(lyrics)\n",
    "                            \n",
    "                            # split with \\n\n",
    "                            lyrics_sentence_list = lyrics.split('\\n')\n",
    "\n",
    "                            # remove punctuation\n",
    "                            lyrics_sentence_list = [re.sub(r'[^\\w\\s]', '', lyrics, re.UNICODE) for lyrics in lyrics_sentence_list]\n",
    "\n",
    "                            '''\n",
    "                            # remove row in lyric has alphabet. use this code if you wanna pure korean lyrics\n",
    "                            # 영어로 된 문장 혹은 알파벳이 포함된 문장 전체를 제거합니다. 순수한글로만 이루어진 가사만 얻고 싶을때 사용합시다.\n",
    "                            lyrics_sentence_list = list(filter(lambda w: not re.match(r'[a-zA-Z]+', w), lyrics_sentence_list)) \n",
    "                            '''\n",
    "\n",
    "                            '''\n",
    "                            # remove only english from row of lyric consist of kor and eng.\n",
    "                            # 한영 혼용 문장에서 오직 영어만을 제거합니다. (한글 부분은 남습니다.) \n",
    "                            lyrics_sentence_list = [re.sub(r'[a-zA-Z]', '', lyrics) for lyrics in lyrics_sentence_list]\n",
    "                            '''\n",
    "\n",
    "                            # remove blank \n",
    "                            lyrics_sentence_list = list(filter(lambda a : a != '', lyrics_sentence_list))   \n",
    "                            lyrics_sentence_list = list(filter(lambda a : a.isspace() != True, lyrics_sentence_list)) \n",
    "                            lyrics_sentence_list = list(filter(lambda a : a.lstrip(), lyrics_sentence_list))\n",
    "                            lyrics_sentence_list = list(filter(lambda a : a.rstrip(), lyrics_sentence_list))\n",
    "\n",
    "                            # remove blank from entire lyric\n",
    "                            lyrics = '\\n'.join(lyrics_sentence_list)\n",
    "\n",
    "                            note = ''\n",
    "\n",
    "                            if trackinfo[4] == 'true':\n",
    "                                note = '19금'\n",
    "                                if trackinfo[2] == 'false':\n",
    "                                    note += '&서비스 종료'\n",
    "                            else:\n",
    "                                if trackinfo[2] == 'false':\n",
    "                                    note = '서비스 종료'\n",
    "                    else :\n",
    "                        lyrics = ''   \n",
    "                        lyrics_sentence_list = ['']    \n",
    "                        note = '가사 등록 안됨'\n",
    "\n",
    "                    artist = artists[rank]\n",
    "\n",
    "                    # TrackInfo Sheet\n",
    "                    years_list.append(year)\n",
    "                    months_list.append(month)\n",
    "                    weeks_list.append(week)\n",
    "                    ranks_list.append(rank + 50*page)\n",
    "                    artists_list.append(artist.text.strip())\n",
    "                    titles_list.append(song.text)\n",
    "                    trackId_list.append(trackinfo[0])\n",
    "                    notes_list.append(note)\n",
    "                    number_of_lines_list.append(len(lyrics_sentence_list))\n",
    "\n",
    "                    # entire lyric\n",
    "                    if trackinfo[0] not in entire_lyric_trackId_list:\n",
    "                        entire_lyric_trackId_list.append(trackinfo[0])\n",
    "                        lyrics_list.append(lyrics)\n",
    "\n",
    "                    # lyric's sentence\n",
    "                    if trackinfo[0] not in lyrics_sentence_trackId_list:\n",
    "                        line = 1                           \n",
    "                        for ly in lyrics_sentence_list:\n",
    "                            lyrics_sentence_trackId_list.append(trackinfo[0])\n",
    "                            sentence_data_list.append(ly)\n",
    "                            line_list.append(line)\n",
    "                            line +=1\n",
    "\n",
    "                    check_has_alphabet = \"False\"\n",
    "                    for ly in lyrics_sentence_list:\n",
    "                        alpahbet_val = re.search('[a-zA-Z]+',ly)\n",
    "                        if(alpahbet_val == None): \n",
    "                            pass\n",
    "                        else:\n",
    "                            if(alpahbet_val[0].isalpha()):\n",
    "                                check_has_alphabet = \"True\"\n",
    "                                break\n",
    "\n",
    "                    has_alphabet_list.append(check_has_alphabet)\n",
    "\n",
    "                    rank += 1 # increase rank, rank is in range 1~100\n",
    "\n",
    "trackInfoSheet_column_list = {\n",
    "'Year': years_list,\n",
    "'Month': months_list,\n",
    "'Week': weeks_list,\n",
    "'Ranking': ranks_list,\n",
    "'Artist': artists_list,\n",
    "'Title': titles_list,\n",
    "'Track_Id' : trackId_list,   \n",
    "'Genre' : genre_list,\n",
    "'Release' : release_list,\n",
    "'Number_Of_Lines' : number_of_lines_list,\n",
    "'Note' : notes_list,\n",
    "'Has_English' : has_alphabet_list,\n",
    "'Lyric': lyrics_list\n",
    "}\n",
    "\n",
    "lyricsDataSheet_column_list = {\n",
    "'Track_Id' : entire_lyric_trackId_list,    \n",
    "'Lyric': lyrics_list,   \n",
    "}\n",
    "\n",
    "SentenceSheet_column_list = {\n",
    "'Track_Id' : lyrics_sentence_trackId_list,\n",
    "'Lyric_Sentence' : sentence_data_list,\n",
    "'Line' : line_list,\n",
    "}\n",
    "\n",
    "df_track_info = pd.DataFrame.from_dict(trackInfoSheet_column_list, orient='index')\n",
    "df_track_info = df_track_info.transpose()\n",
    "\n",
    "df_lyric_data = pd.DataFrame.from_dict(lyricsDataSheet_column_list, orient='index')\n",
    "df_lyric_data = df_lyric_data.transpose()\n",
    "\n",
    "df_sentence_data = pd.DataFrame.from_dict(SentenceSheet_column_list, orient='index')\n",
    "df_sentence_data = df_sentence_data.transpose()\n",
    "\n",
    "writer = pd.ExcelWriter(\"2019년 1월.xlsx\")\n",
    "\n",
    "df_track_info.to_excel(writer, sheet_name='Top100_chart_track_info', startrow=1, header=True)\n",
    "df_lyric_data.to_excel(writer, sheet_name='Top100_lyrics_data', startrow=1, header=True)\n",
    "df_sentence_data.to_excel(writer, sheet_name='Sentence_data', startrow=1, header=True)\n",
    "\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
